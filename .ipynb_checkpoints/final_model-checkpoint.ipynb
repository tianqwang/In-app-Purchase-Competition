{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generating and Engineering\n",
    "This notebook is for generating the features put into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages Load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files\n",
    "events = pd.read_pickle('data/events.pkl')\n",
    "attr = pd.read_pickle('data/attr_long.pkl')\n",
    "session = pd.read_pickle('data/session.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>event</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>event_value</th>\n",
       "      <th>user_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5558845121177764917</td>\n",
       "      <td>45</td>\n",
       "      <td>1542215397132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5558845121177764917</td>\n",
       "      <td>45</td>\n",
       "      <td>1542215484895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7689508378645584666</td>\n",
       "      <td>.m5100869650219008</td>\n",
       "      <td>1541124410372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2201961907282901522</td>\n",
       "      <td>4</td>\n",
       "      <td>1543713091129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201961907282901522</td>\n",
       "      <td>6</td>\n",
       "      <td>1543713093116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_id               event  event_timestamp  event_value  \\\n",
       "0  5558845121177764917                  45    1542215397132          0.0   \n",
       "1  5558845121177764917                  45    1542215484895          0.0   \n",
       "2  7689508378645584666  .m5100869650219008    1541124410372          0.0   \n",
       "3  2201961907282901522                   4    1543713091129          0.0   \n",
       "4  2201961907282901522                   6    1543713093116          0.0   \n",
       "\n",
       "                                        user_id_hash  \n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "1  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "2  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "3  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "4  9943447915df3a45fd6720a026af905b6da6b56a37701b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our predictions are based on users, we need to create features on user base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>timezone</th>\n",
       "      <th>timezone_offset</th>\n",
       "      <th>previous_sessions_duration</th>\n",
       "      <th>user_created_timestamp</th>\n",
       "      <th>is_user_first_session</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locale</th>\n",
       "      <th>os_name</th>\n",
       "      <th>session_index</th>\n",
       "      <th>device_id</th>\n",
       "      <th>user_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5558845121177764917</td>\n",
       "      <td>1542215364580</td>\n",
       "      <td>Asia/Manila</td>\n",
       "      <td>28800000.0</td>\n",
       "      <td>25837591</td>\n",
       "      <td>1538874289458</td>\n",
       "      <td>False</td>\n",
       "      <td>PH</td>\n",
       "      <td>00</td>\n",
       "      <td>makati</td>\n",
       "      <td>14.554729</td>\n",
       "      <td>121.024445</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>Android OS</td>\n",
       "      <td>30</td>\n",
       "      <td>546a3d98-d540-4e72-ad82-9ebd64e0839b</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18781111175537580</td>\n",
       "      <td>1539215568666</td>\n",
       "      <td>Asia/Manila</td>\n",
       "      <td>28800000.0</td>\n",
       "      <td>11343848</td>\n",
       "      <td>1538874289458</td>\n",
       "      <td>False</td>\n",
       "      <td>PH</td>\n",
       "      <td>00</td>\n",
       "      <td>makati</td>\n",
       "      <td>14.554729</td>\n",
       "      <td>121.024445</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>Android OS</td>\n",
       "      <td>10</td>\n",
       "      <td>546a3d98-d540-4e72-ad82-9ebd64e0839b</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477540082628742048</td>\n",
       "      <td>1540120743010</td>\n",
       "      <td>Asia/Manila</td>\n",
       "      <td>28800000.0</td>\n",
       "      <td>13499724</td>\n",
       "      <td>1538874289458</td>\n",
       "      <td>False</td>\n",
       "      <td>PH</td>\n",
       "      <td>11</td>\n",
       "      <td>davao city</td>\n",
       "      <td>7.190708</td>\n",
       "      <td>125.455338</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>Android OS</td>\n",
       "      <td>13</td>\n",
       "      <td>546a3d98-d540-4e72-ad82-9ebd64e0839b</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8184875317380844086</td>\n",
       "      <td>1542671625528</td>\n",
       "      <td>Asia/Manila</td>\n",
       "      <td>28800000.0</td>\n",
       "      <td>32788010</td>\n",
       "      <td>1538874289458</td>\n",
       "      <td>False</td>\n",
       "      <td>PH</td>\n",
       "      <td>00</td>\n",
       "      <td>makati</td>\n",
       "      <td>14.554729</td>\n",
       "      <td>121.024445</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>Android OS</td>\n",
       "      <td>41</td>\n",
       "      <td>546a3d98-d540-4e72-ad82-9ebd64e0839b</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4706180700083856343</td>\n",
       "      <td>1538997913013</td>\n",
       "      <td>Asia/Manila</td>\n",
       "      <td>28800000.0</td>\n",
       "      <td>5872534</td>\n",
       "      <td>1538874289458</td>\n",
       "      <td>False</td>\n",
       "      <td>PH</td>\n",
       "      <td>11</td>\n",
       "      <td>davao city</td>\n",
       "      <td>7.190708</td>\n",
       "      <td>125.455338</td>\n",
       "      <td>en_GB</td>\n",
       "      <td>Android OS</td>\n",
       "      <td>4</td>\n",
       "      <td>546a3d98-d540-4e72-ad82-9ebd64e0839b</td>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_id  start_timestamp     timezone  timezone_offset  \\\n",
       "0  5558845121177764917    1542215364580  Asia/Manila       28800000.0   \n",
       "1    18781111175537580    1539215568666  Asia/Manila       28800000.0   \n",
       "2  1477540082628742048    1540120743010  Asia/Manila       28800000.0   \n",
       "3  8184875317380844086    1542671625528  Asia/Manila       28800000.0   \n",
       "4  4706180700083856343    1538997913013  Asia/Manila       28800000.0   \n",
       "\n",
       "   previous_sessions_duration  user_created_timestamp  is_user_first_session  \\\n",
       "0                    25837591           1538874289458                  False   \n",
       "1                    11343848           1538874289458                  False   \n",
       "2                    13499724           1538874289458                  False   \n",
       "3                    32788010           1538874289458                  False   \n",
       "4                     5872534           1538874289458                  False   \n",
       "\n",
       "  country region        city   latitude   longitude locale     os_name  \\\n",
       "0      PH     00      makati  14.554729  121.024445  en_GB  Android OS   \n",
       "1      PH     00      makati  14.554729  121.024445  en_GB  Android OS   \n",
       "2      PH     11  davao city   7.190708  125.455338  en_GB  Android OS   \n",
       "3      PH     00      makati  14.554729  121.024445  en_GB  Android OS   \n",
       "4      PH     11  davao city   7.190708  125.455338  en_GB  Android OS   \n",
       "\n",
       "   session_index                             device_id  \\\n",
       "0             30  546a3d98-d540-4e72-ad82-9ebd64e0839b   \n",
       "1             10  546a3d98-d540-4e72-ad82-9ebd64e0839b   \n",
       "2             13  546a3d98-d540-4e72-ad82-9ebd64e0839b   \n",
       "3             41  546a3d98-d540-4e72-ad82-9ebd64e0839b   \n",
       "4              4  546a3d98-d540-4e72-ad82-9ebd64e0839b   \n",
       "\n",
       "                                        user_id_hash  \n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "1  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "2  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "3  9943447915df3a45fd6720a026af905b6da6b56a37701b...  \n",
       "4  9943447915df3a45fd6720a026af905b6da6b56a37701b...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-01 07:00:04\n",
      "2018-12-14 23:59:59\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcfromtimestamp(session.start_timestamp.min()/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(datetime.utcfromtimestamp(session.start_timestamp.max()/1000).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create labels during period Dec 1st and Dec 14th, and use features from Oct 1st to Nov 30th to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543622399000.0\n",
      "1544227199000.0\n"
     ]
    }
   ],
   "source": [
    "# Get the time stamp to split data.\n",
    "print(datetime(2018,11,30,23,59,59).timestamp()*1000)\n",
    "print(datetime(2018,12,7,23,59,59).timestamp()*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data specifically for df feature generation\n",
    "events_training = events[events.event_timestamp<=1543622399000]\n",
    "session_training = session[session.start_timestamp<=1543622399000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label1 7-day purchase\n",
    "purchase_user_7 = set(events[(events.event=='8') & (events.event_timestamp>1543622399000) & (events.event_timestamp<=1544227199000)].user_id_hash)\n",
    "# Label2 14-day purchase\n",
    "purchase_user_14 = set(events[(events.event=='8') & (events.event_timestamp>1543622399000)].user_id_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4729"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(purchase_user_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(purchase_user_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Frame for df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame(data = list(set(events.user_id_hash)&set(session.user_id_hash)), \n",
    "                        columns = ['user_id_hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_create(df, label_1='user_purchase_binary_7_days', label_2='user_purchase_binary_14_days'):\n",
    "    df[label_1] = df['user_id_hash'].apply(lambda x: x in purchase_user_7)\n",
    "    df[label_2] = df['user_id_hash'].apply(lambda x: x in purchase_user_14)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training  = label_create(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619423, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1b7e06ceb4d33e7e7152ccca344c793700d52c8464e9c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ae81c836e37bdde4408585ced58a5602e0f946286e36e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b524a272f9dc01b6dfa57ecd23fe8a85b628c7ac8cac7e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad244155c390b9b6c87da920c3d68cbafb7fd7968efa9c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a632aad4c752164a6835f25eb325151f661b1ab549482c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  a1b7e06ceb4d33e7e7152ccca344c793700d52c8464e9c...   \n",
       "1  4ae81c836e37bdde4408585ced58a5602e0f946286e36e...   \n",
       "2  b524a272f9dc01b6dfa57ecd23fe8a85b628c7ac8cac7e...   \n",
       "3  ad244155c390b9b6c87da920c3d68cbafb7fd7968efa9c...   \n",
       "4  a632aad4c752164a6835f25eb325151f661b1ab549482c...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                        False                         False  \n",
       "1                        False                         False  \n",
       "2                        False                         False  \n",
       "3                        False                         False  \n",
       "4                        False                         False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training features\n",
    "We will create user-based features one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_gap = (1544227199000-1543622399000)/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generate(df, events_df, session_df):\n",
    "    window_max = events_df['event_timestamp'].max()\n",
    "    window_1_week_before = window_max - 7*day_gap\n",
    "    window_2_week_before = window_max - 14*day_gap\n",
    "    window_3_week_before = window_max - 21*day_gap\n",
    "    \n",
    "    print(df.shape)\n",
    "    # Feature one: event_count\n",
    "    count = events_df.groupby('user_id_hash').event.count()\n",
    "    df['event_count'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature two: purchase_count_1_week\n",
    "    count = events_df[(events_df.event=='8')&(events_df.event_timestamp>window_1_week_before)].groupby('user_id_hash').event.count()\n",
    "    df['purchase_count_1_week'] = df.user_id_hash.map(count)\n",
    "    # Feature two: purchase_count_2_week\n",
    "    count = events_df[(events_df.event=='8')&(events_df.event_timestamp>window_2_week_before)&(events_df.event_timestamp<=window_1_week_before)].groupby('user_id_hash').event.count()\n",
    "    df['purchase_count_2_week'] = df.user_id_hash.map(count)\n",
    "    # Feature two: purchase_count_3_week\n",
    "    count = events_df[(events_df.event=='8')&(events_df.event_timestamp>window_3_week_before)&(events_df.event_timestamp<=window_2_week_before)].groupby('user_id_hash').event.count()\n",
    "    df['purchase_count_3_week'] = df.user_id_hash.map(count)\n",
    "    # Feature two: purchase_count_4_week\n",
    "    count = events_df[(events_df.event=='8')&(events_df.event_timestamp<=window_3_week_before)].groupby('user_id_hash').event.count()\n",
    "    df['purchase_count_4_week'] = df.user_id_hash.map(count)\n",
    "    print(df.shape)\n",
    "    # Feature three: session_count    \n",
    "    count = events_df.groupby('user_id_hash').session_id.count()\n",
    "    df['session_count'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature four: country\n",
    "    country = session_df.groupby('user_id_hash').country.first()\n",
    "    df['country'] = df.user_id_hash.map(country)\n",
    "    \n",
    "    # Feature five: OS\n",
    "    os = session_df.groupby('user_id_hash').os_name.first()\n",
    "    df['os_name'] = df.user_id_hash.map(os)\n",
    "\n",
    "    # Feature 11: city\n",
    "    \n",
    "    city = session_df.groupby('user_id_hash').city.first()\n",
    "    df['city'] = df.user_id_hash.map(city)\n",
    "    \n",
    "    \n",
    "    # Feature 24: region\n",
    "    \n",
    "    region = session_df.groupby('user_id_hash').region.first()\n",
    "    df['region'] = df.user_id_hash.map(region)\n",
    "    print(df.shape)    \n",
    "    # Feature six: session_duration\n",
    "    duration = session_df.groupby('user_id_hash').previous_sessions_duration.mean()\n",
    "    df['mean_sessions_duration'] = df.user_id_hash.map(duration)\n",
    "    \n",
    "    # Feature seven: spend\n",
    "    spend = events_df.groupby('user_id_hash').event_value.sum()\n",
    "    df['spend'] = df.user_id_hash.map(spend)\n",
    "    \n",
    "    # Feature eight: event_gap    \n",
    "    event_gap = events_df.groupby('user_id_hash').event_timestamp.max()\n",
    "    event_gap = window_max - event_gap\n",
    "    df['event_gap'] = df.user_id_hash.map(event_gap)\n",
    "        \n",
    "    # Feature nine: session_gap\n",
    "    session_gap = session_df.groupby('user_id_hash').start_timestamp.max()\n",
    "    session_gap = window_max - session_gap\n",
    "    df['session_gap'] = df.user_id_hash.map(session_gap)    \n",
    "\n",
    "    # Feature 25: purchase_gap\n",
    "    purchase_gap = events_df[events_df.event=='8'].groupby('user_id_hash').event_timestamp.max()\n",
    "    purchase_gap = window_max - purchase_gap\n",
    "    df['purchase_gap'] = df.user_id_hash.map(purchase_gap) \n",
    "    \n",
    "    # Feature ten: life_time\n",
    "    life_time = session_df.groupby('user_id_hash').user_created_timestamp.max()\n",
    "    life_time = window_max - life_time\n",
    "    df['life_time'] = df.user_id_hash.map(life_time)     \n",
    "    print(df.shape)    \n",
    "#     # Feature 12: num_places\n",
    "#     num_places = session_df.groupby('user_id_hash').latitude.nunique('latitude')\n",
    "#     df['num_places'] = df.user_id_hash.map(num_places) \n",
    "    \n",
    "    # Feature 13: event_45    \n",
    "    count = events_df[events_df.event=='45'].groupby('user_id_hash').event.count()\n",
    "    df['event_45'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 14: event_1\n",
    "    count = events_df[events_df.event=='1'].groupby('user_id_hash').event.count()\n",
    "    df['event_1'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 15: event_5\n",
    "    count = events_df[events_df.event=='5'].groupby('user_id_hash').event.count()\n",
    "    df['event_5'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 16: event_6\n",
    "    count = events_df[events_df.event=='6'].groupby('user_id_hash').event.count()\n",
    "    df['event_6'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 17: event_14\n",
    "    count = events_df[events_df.event=='14'].groupby('user_id_hash').event.count()\n",
    "    df['event_14'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 18: event_4\n",
    "    count = events_df[events_df.event=='4'].groupby('user_id_hash').event.count()\n",
    "    df['event_4'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 19: event_40\n",
    "    count = events_df[events_df.event=='40'].groupby('user_id_hash').event.count()\n",
    "    df['event_40'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 20: event_7\n",
    "    count = events_df[events_df.event=='7'].groupby('user_id_hash').event.count()\n",
    "    df['event_7'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 21: event_41\n",
    "    count = events_df[events_df.event=='41'].groupby('user_id_hash').event.count()\n",
    "    df['event_41'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 22: event_3\n",
    "    count = events_df[events_df.event=='3'].groupby('user_id_hash').event.count()\n",
    "    df['event_3'] = df.user_id_hash.map(count)\n",
    "    \n",
    "    # Feature 23: event_42\n",
    "    count = events_df[events_df.event=='42'].groupby('user_id_hash').event.count()\n",
    "    df['event_42'] = df.user_id_hash.map(count)\n",
    "    print(df.shape)    \n",
    "    # Feature 23: event_42\n",
    "    attr_1 = attr[attr.attribute==1].groupby('user_id_hash').attribute_value.astype(np.float32).mean()\n",
    "    df['attr_1'] = df.user_id_hash.map(attr_1)\n",
    "    \n",
    "    attr_13 = attr[attr.attribute==13].groupby('user_id_hash').attribute_value.astype(np.float32).mean()\n",
    "    df['attr_13'] = df.user_id_hash.map(attr_13)\n",
    "    \n",
    "    attr_14 = attr[attr.attribute==14].groupby('user_id_hash').attribute_value.astype(np.float32).mean()\n",
    "    df['attr_14'] = df.user_id_hash.map(attr_14)\n",
    "    \n",
    "    attr_15 = attr[attr.attribute==15].groupby('user_id_hash').attribute_value.astype(np.float32).mean()\n",
    "    df['attr_15'] = df.user_id_hash.map(attr_15)\n",
    "    \n",
    "    attr_16 = attr[attr.attribute==16].groupby('user_id_hash').attribute_value.astype(np.float32).mean()\n",
    "    df['attr_16'] = df.user_id_hash.map(attr_16)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619423, 5)\n",
      "(619423, 8)\n",
      "(619423, 13)\n",
      "(619423, 19)\n",
      "(619423, 30)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Cannot access callable attribute 'astype' of 'SeriesGroupBy' objects, try using the 'apply' method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c8d75ba8d436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-5058b4cd35bc>\u001b[0m in \u001b[0;36mfeature_generate\u001b[0;34m(df, events_df, session_df)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Feature 23: event_42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mattr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id_hash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attr_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         raise AttributeError(\"%r object has no attribute %r\" %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_make_wrapper\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    568\u001b[0m                    \"using the 'apply' method\".format(kind, name,\n\u001b[1;32m    569\u001b[0m                                                      type(self).__name__))\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_group_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Cannot access callable attribute 'astype' of 'SeriesGroupBy' objects, try using the 'apply' method"
     ]
    }
   ],
   "source": [
    "training = feature_generate(training, events_training, session_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_pickle('training_att.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets wrap up all feature generating procedures and use it in prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = feature_generate(submission, events, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit2 = feature_encoding(submit, events, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_pickle('prediction.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e469dfaed039ead9110165d9bc457acb11609ca34057dc...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  e469dfaed039ead9110165d9bc457acb11609ca34057dc...   \n",
       "1  afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...   \n",
       "2  fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...   \n",
       "3  00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...   \n",
       "4  0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                         0.01                          0.02  \n",
       "1                         0.01                          0.02  \n",
       "2                         0.01                          0.02  \n",
       "3                         0.01                          0.02  \n",
       "4                         0.01                          0.02  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop(columns =['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name','city','region'])\n",
    "y = training['user_purchase_binary_7_days']\n",
    "X_test = submit2.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name','city','region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619423, 25)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312568, 25)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 40,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.01,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.7,\n",
    "         'reg_lambda': 5,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.8,\n",
    "#          'min_gain_to_split': 0.01,\n",
    "#          'min_child_weight': 20,\n",
    "         'num_threads': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Tue Feb 19 00:27:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.975062\tvalid_1's auc: 0.9722\n",
      "[600]\ttraining's auc: 0.977128\tvalid_1's auc: 0.973809\n",
      "[900]\ttraining's auc: 0.978228\tvalid_1's auc: 0.974338\n",
      "[1200]\ttraining's auc: 0.978891\tvalid_1's auc: 0.974539\n",
      "[1500]\ttraining's auc: 0.97951\tvalid_1's auc: 0.974745\n",
      "[1800]\ttraining's auc: 0.980019\tvalid_1's auc: 0.974835\n",
      "[2100]\ttraining's auc: 0.980511\tvalid_1's auc: 0.974906\n",
      "[2400]\ttraining's auc: 0.981\tvalid_1's auc: 0.975005\n",
      "[2700]\ttraining's auc: 0.981468\tvalid_1's auc: 0.975052\n",
      "[3000]\ttraining's auc: 0.981894\tvalid_1's auc: 0.97512\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data,num_boost_round=20000,\n",
    "                      valid_sets = [train_data, valid_data], \n",
    "                      verbose_eval=300, \n",
    "                      early_stopping_rounds = 200)\n",
    "            \n",
    "    #y_pred_valid = model.predict(X_valid)\n",
    "    prediction += model.predict(X_test, num_iteration=model.best_iteration)/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lgb_prediction_1', prediction1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Mon Feb 18 04:12:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.974345\tvalid_1's auc: 0.971998\n",
      "[600]\ttraining's auc: 0.976271\tvalid_1's auc: 0.973568\n",
      "[900]\ttraining's auc: 0.977183\tvalid_1's auc: 0.97389\n",
      "[1200]\ttraining's auc: 0.978002\tvalid_1's auc: 0.974197\n",
      "[1500]\ttraining's auc: 0.978594\tvalid_1's auc: 0.974382\n",
      "[1800]\ttraining's auc: 0.979117\tvalid_1's auc: 0.974516\n",
      "[2100]\ttraining's auc: 0.979524\tvalid_1's auc: 0.974564\n",
      "[2400]\ttraining's auc: 0.979943\tvalid_1's auc: 0.974607\n",
      "Early stopping, best iteration is:\n",
      "[2344]\ttraining's auc: 0.979854\tvalid_1's auc: 0.97465\n",
      "Fold 1 started at Mon Feb 18 04:14:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.974003\tvalid_1's auc: 0.974068\n",
      "[600]\ttraining's auc: 0.975958\tvalid_1's auc: 0.975329\n",
      "[900]\ttraining's auc: 0.976866\tvalid_1's auc: 0.975858\n",
      "[1200]\ttraining's auc: 0.977602\tvalid_1's auc: 0.976209\n",
      "[1500]\ttraining's auc: 0.978206\tvalid_1's auc: 0.976438\n",
      "[1800]\ttraining's auc: 0.978764\tvalid_1's auc: 0.976607\n",
      "[2100]\ttraining's auc: 0.979184\tvalid_1's auc: 0.976712\n",
      "[2400]\ttraining's auc: 0.979597\tvalid_1's auc: 0.976799\n",
      "[2700]\ttraining's auc: 0.979955\tvalid_1's auc: 0.976838\n",
      "[3000]\ttraining's auc: 0.980298\tvalid_1's auc: 0.97691\n",
      "[3300]\ttraining's auc: 0.980614\tvalid_1's auc: 0.976937\n",
      "[3600]\ttraining's auc: 0.980898\tvalid_1's auc: 0.976964\n",
      "[3900]\ttraining's auc: 0.981196\tvalid_1's auc: 0.976988\n",
      "Early stopping, best iteration is:\n",
      "[3961]\ttraining's auc: 0.981263\tvalid_1's auc: 0.977007\n",
      "Fold 2 started at Mon Feb 18 04:18:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.974308\tvalid_1's auc: 0.970994\n",
      "[600]\ttraining's auc: 0.976221\tvalid_1's auc: 0.973401\n",
      "[900]\ttraining's auc: 0.977216\tvalid_1's auc: 0.974187\n",
      "[1200]\ttraining's auc: 0.977897\tvalid_1's auc: 0.974603\n",
      "[1500]\ttraining's auc: 0.978348\tvalid_1's auc: 0.974744\n",
      "[1800]\ttraining's auc: 0.978789\tvalid_1's auc: 0.974924\n",
      "[2100]\ttraining's auc: 0.979156\tvalid_1's auc: 0.975045\n",
      "[2400]\ttraining's auc: 0.979539\tvalid_1's auc: 0.975159\n",
      "[2700]\ttraining's auc: 0.979891\tvalid_1's auc: 0.975244\n",
      "[3000]\ttraining's auc: 0.980305\tvalid_1's auc: 0.975328\n",
      "[3300]\ttraining's auc: 0.980641\tvalid_1's auc: 0.975406\n",
      "[3600]\ttraining's auc: 0.980934\tvalid_1's auc: 0.975453\n",
      "[3900]\ttraining's auc: 0.981187\tvalid_1's auc: 0.975485\n",
      "[4200]\ttraining's auc: 0.981458\tvalid_1's auc: 0.975567\n",
      "[4500]\ttraining's auc: 0.981695\tvalid_1's auc: 0.975606\n",
      "[4800]\ttraining's auc: 0.981973\tvalid_1's auc: 0.975626\n",
      "Early stopping, best iteration is:\n",
      "[4850]\ttraining's auc: 0.982019\tvalid_1's auc: 0.975636\n",
      "Fold 3 started at Mon Feb 18 04:23:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.974323\tvalid_1's auc: 0.973804\n",
      "[600]\ttraining's auc: 0.976148\tvalid_1's auc: 0.974308\n",
      "[900]\ttraining's auc: 0.977153\tvalid_1's auc: 0.974861\n",
      "[1200]\ttraining's auc: 0.97774\tvalid_1's auc: 0.975185\n",
      "[1500]\ttraining's auc: 0.978279\tvalid_1's auc: 0.975449\n",
      "[1800]\ttraining's auc: 0.978779\tvalid_1's auc: 0.975584\n",
      "[2100]\ttraining's auc: 0.979208\tvalid_1's auc: 0.975731\n",
      "[2400]\ttraining's auc: 0.979599\tvalid_1's auc: 0.975795\n",
      "[2700]\ttraining's auc: 0.979942\tvalid_1's auc: 0.975841\n",
      "[3000]\ttraining's auc: 0.98024\tvalid_1's auc: 0.975898\n",
      "[3300]\ttraining's auc: 0.980587\tvalid_1's auc: 0.975973\n",
      "[3600]\ttraining's auc: 0.980885\tvalid_1's auc: 0.976028\n",
      "[3900]\ttraining's auc: 0.981179\tvalid_1's auc: 0.976109\n",
      "Early stopping, best iteration is:\n",
      "[3924]\ttraining's auc: 0.981202\tvalid_1's auc: 0.976119\n",
      "Fold 4 started at Mon Feb 18 04:27:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.973944\tvalid_1's auc: 0.973824\n",
      "[600]\ttraining's auc: 0.975999\tvalid_1's auc: 0.97529\n",
      "[900]\ttraining's auc: 0.976983\tvalid_1's auc: 0.975682\n",
      "[1200]\ttraining's auc: 0.97772\tvalid_1's auc: 0.975813\n",
      "[1500]\ttraining's auc: 0.978299\tvalid_1's auc: 0.975918\n",
      "[1800]\ttraining's auc: 0.978782\tvalid_1's auc: 0.975911\n",
      "Early stopping, best iteration is:\n",
      "[1670]\ttraining's auc: 0.978593\tvalid_1's auc: 0.975939\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data,num_boost_round=20000,\n",
    "                      valid_sets = [train_data, valid_data], \n",
    "                      verbose_eval=300, \n",
    "                      early_stopping_rounds = 200)\n",
    "            \n",
    "    #y_pred_valid = model.predict(X_valid)\n",
    "    prediction += model.predict(X_test, num_iteration=model.best_iteration)/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])\n",
    "y = training['user_purchase_binary_14_days']\n",
    "X_test = submit.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data,num_boost_round=20000,\n",
    "                      valid_sets = [train_data, valid_data], \n",
    "                      verbose_eval=300, \n",
    "                      early_stopping_rounds = 200)\n",
    "            \n",
    "    #y_pred_valid = model.predict(X_valid)\n",
    "    prediction += model.predict(X_test, num_iteration=model.best_iteration)/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = prediction\n",
    "np.save('lgb_prediction_2', prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 40,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.01,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.7,\n",
    "         'reg_lambda': 5,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.8,\n",
    "#          'min_gain_to_split': 0.01,\n",
    "#          'min_child_weight': 20,\n",
    "         'num_threads': 8}\n",
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])\n",
    "y = training['user_purchase_binary_7_days']\n",
    "X_test = submit.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import catboost as cab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.2'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cab.CatBoostClassifier(loss_function=\"Logloss\",\n",
    "                           eval_metric=\"AUC\",\n",
    "                           task_type=\"CPU\",\n",
    "                           learning_rate=0.01,\n",
    "                           iterations=10000,\n",
    "                           random_seed=42,\n",
    "                           od_type=\"Iter\",\n",
    "                           depth=10,\n",
    "                           early_stopping_rounds=300\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "target = y.apply(lambda x: int(x))\n",
    "y_valid_pred = 0 * target\n",
    "y_test_pred = 0\n",
    "for idx, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:], X.iloc[valid_index,:]\n",
    "    _train = cab.Pool(X_train, label=y_train)\n",
    "    _valid = cab.Pool(X_valid, label=y_valid)\n",
    "    print( \"\\nFold \", idx)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=200,\n",
    "                          plot=True\n",
    "                         )\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_valid_pred.iloc[valid_index] = pred\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "y_test_pred /= n_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cab_prediction_1', y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training['user_purchase_binary_14_days']\n",
    "from sklearn.metrics import roc_auc_score\n",
    "target = y.apply(lambda x: int(x))\n",
    "y_valid_pred = 0 * target\n",
    "y_test_pred = 0\n",
    "for idx, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:], X.iloc[valid_index,:]\n",
    "    _train = cab.Pool(X_train, label=y_train)\n",
    "    _valid = cab.Pool(X_valid, label=y_valid)\n",
    "    print( \"\\nFold \", idx)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=200,\n",
    "                          plot=True\n",
    "                         )\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_valid_pred.iloc[valid_index] = pred\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "y_test_pred /= n_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cab_prediction_2', y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_count</th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>session_count</th>\n",
       "      <th>mean_sessions_duration</th>\n",
       "      <th>spend</th>\n",
       "      <th>event_gap</th>\n",
       "      <th>session_gap</th>\n",
       "      <th>life_time</th>\n",
       "      <th>num_places</th>\n",
       "      <th>event_45</th>\n",
       "      <th>...</th>\n",
       "      <th>event_5</th>\n",
       "      <th>event_6</th>\n",
       "      <th>event_14</th>\n",
       "      <th>event_4</th>\n",
       "      <th>event_40</th>\n",
       "      <th>event_7</th>\n",
       "      <th>event_41</th>\n",
       "      <th>event_3</th>\n",
       "      <th>event_42</th>\n",
       "      <th>purchase_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>356544.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.169025e+09</td>\n",
       "      <td>4.169058e+09</td>\n",
       "      <td>4.219028e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.962124e+09</td>\n",
       "      <td>2.068505e+09</td>\n",
       "      <td>2.068521e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>388631.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.259103e+09</td>\n",
       "      <td>3.448174e+09</td>\n",
       "      <td>4.132000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9200582.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.712367e+09</td>\n",
       "      <td>2.714804e+09</td>\n",
       "      <td>4.368928e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.332535e+09</td>\n",
       "      <td>5.507037e+09</td>\n",
       "      <td>5.507037e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_count  purchase_count  session_count  mean_sessions_duration  spend  \\\n",
       "0         26.0             0.0            2.0               356544.00    0.0   \n",
       "1         50.0             0.0            1.0                    0.00    0.0   \n",
       "2         31.0             0.0            4.0               388631.25    0.0   \n",
       "3        207.0             0.0           10.0              9200582.90    0.0   \n",
       "4          5.0             0.0            1.0                    0.00    0.0   \n",
       "\n",
       "      event_gap   session_gap     life_time  num_places  event_45  \\\n",
       "0  4.169025e+09  4.169058e+09  4.219028e+09         1.0      17.0   \n",
       "1  1.962124e+09  2.068505e+09  2.068521e+09         1.0      31.0   \n",
       "2  3.259103e+09  3.448174e+09  4.132000e+09         2.0      19.0   \n",
       "3  2.712367e+09  2.714804e+09  4.368928e+09         2.0     142.0   \n",
       "4  5.332535e+09  5.507037e+09  5.507037e+09         1.0       0.0   \n",
       "\n",
       "       ...       event_5  event_6  event_14  event_4  event_40  event_7  \\\n",
       "0      ...           1.0      1.0       3.0      0.0       0.0      1.0   \n",
       "1      ...           3.0      3.0       3.0      3.0       0.0      1.0   \n",
       "2      ...           1.0      1.0       3.0      0.0       0.0      2.0   \n",
       "3      ...           9.0      8.0       6.0      7.0       5.0      4.0   \n",
       "4      ...           0.0      0.0       0.0      0.0       0.0      0.0   \n",
       "\n",
       "   event_41  event_3  event_42  purchase_gap  \n",
       "0       0.0      0.0       0.0           NaN  \n",
       "1       0.0      0.0       0.0           NaN  \n",
       "2       0.0      0.0       0.0           NaN  \n",
       "3       5.0      4.0       2.0           NaN  \n",
       "4       0.0      0.0       0.0           NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lgb_prediction_1', prediction1)y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])\n",
    "y = training['user_purchase_binary_7_days']\n",
    "X_test = submit.drop(columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days','country','os_name', 'city', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['user_purchase_binary_7_days'] = prediction1\n",
    "submission['user_purchase_binary_14_days'] = prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission0217.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 32.6M/32.6M [00:02<00:00, 16.1MB/s]\n",
      "Successfully submitted to Predict in-app purchases"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit predict-in-app-purchase -f submission0217.csv -m \"Using full 11 features and model on lgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
