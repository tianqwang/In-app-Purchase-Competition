{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in training/validation/full data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('train_df')\n",
    "val_df = pd.read_feather('val_df')\n",
    "full_df = pd.read_feather('full_data_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting random forest model to the 7 day purchase labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=7, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_7day = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=7, class_weight='balanced_subsample')\n",
    "rf_7day.fit(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1), train_df['purchase_7day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['purchase_7day']\n",
    "y_val = val_df['purchase_7day']\n",
    "y_fit = rf_7day.predict(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_fit_prob = rf_7day.predict_proba(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_pred = rf_7day.predict(val_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_pred_prob = rf_7day.predict_proba(val_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.937\n",
      "Validation AUC: 0.922\n"
     ]
    }
   ],
   "source": [
    "print(\"Training AUC: %.3f\" % roc_auc_score(y_train, y_fit_prob[:, 1]))\n",
    "print(\"Validation AUC: %.3f\" % roc_auc_score(y_val, y_pred_prob[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting random forest model to the 14 day purchase labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=7, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_14day = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=7, class_weight='balanced_subsample')\n",
    "rf_14day.fit(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1), train_df['purchase_14day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['purchase_14day']\n",
    "y_val = val_df['purchase_14day']\n",
    "y_fit = rf_14day.predict(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_fit_prob = rf_14day.predict_proba(train_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_pred = rf_14day.predict(val_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))\n",
    "y_pred_prob = rf_14day.predict_proba(val_df.drop(['user_id_hash', 'purchase_7day', 'purchase_14day'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.929\n",
      "Validation AUC: 0.913\n"
     ]
    }
   ],
   "source": [
    "print(\"Training AUC: %.3f\" % roc_auc_score(y_train, y_fit_prob[:, 1]))\n",
    "print(\"Validation AUC: %.3f\" % roc_auc_score(y_val, y_pred_prob[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions from the features computed on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_7 = rf_7day.predict(full_df.drop(['user_id_hash'], axis=1))\n",
    "y_pred_prob_7 = rf_7day.predict_proba(full_df.drop(['user_id_hash'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_14 = rf_14day.predict(full_df.drop(['user_id_hash'], axis=1))\n",
    "y_pred_prob_14 = rf_14day.predict_proba(full_df.drop(['user_id_hash'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate([np.array(full_df['user_id_hash']).reshape(-1,1), y_pred_prob_7[:,1].reshape(-1,1), y_pred_prob_14[:,1].reshape(-1,1)], axis=1)\n",
    "predictions = pd.DataFrame(predictions, columns=['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating prediction file for kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/christopherolley/data/Leanplum-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"%s/sample_submission_2.csv\" % data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions = pd.merge(pd.DataFrame(sample_submission['user_id_hash']), predictions, on='user_id_hash', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill any users we don't have any data on with zeros (low probability of purchase if didn't exist before two week test window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e469dfaed039ead9110165d9bc457acb11609ca34057dc...</td>\n",
       "      <td>0.048074</td>\n",
       "      <td>0.050355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...</td>\n",
       "      <td>0.154817</td>\n",
       "      <td>0.187705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...</td>\n",
       "      <td>0.220782</td>\n",
       "      <td>0.248832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...</td>\n",
       "      <td>0.435151</td>\n",
       "      <td>0.449922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  e469dfaed039ead9110165d9bc457acb11609ca34057dc...   \n",
       "1  afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...   \n",
       "2  fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...   \n",
       "3  00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...   \n",
       "4  0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                     0.048074                      0.050355  \n",
       "1                     0.154817                      0.187705  \n",
       "2                     0.220782                      0.248832  \n",
       "3                     0.435151                      0.449922  \n",
       "4                     0.000000                      0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions.to_csv('kaggle_predictions_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
